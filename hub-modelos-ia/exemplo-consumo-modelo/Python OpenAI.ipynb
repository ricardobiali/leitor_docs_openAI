{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de uso Python OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importante**\n",
    "\n",
    "Este notebook utiliza um recurso que só existe nas versões da lib openai anteriores à 1.x. Para executá-lo, instale a openai==0.28.1. O outro notebook permite usar a versão mais recente da lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai  # pip install openai\n",
    "from dotenv import load_dotenv  # pip install python-dotenv\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "\n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('config.ini', 'UTF-8')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = './petrobras-ca-root.pem'\n",
    "\n",
    "openai.api_type = 'azure'\n",
    "openai.api_base = config['OPENAI']['OPENAI_API_BASE']\n",
    "openai.api_version = config['OPENAI']['OPENAI_API_VERSION']\n",
    "openai.api_key = 'not-used'\n",
    "\n",
    "# Configuração do prefixo do APIM, que é diferente do prefixo da Azure (não documentada)\n",
    "from openai.api_resources.abstract import APIResource\n",
    "APIResource.azure_api_prefix = config['OPENAI']['AZURE_OPENAI_PREFIX']\n",
    "\n",
    "# Configura headers\n",
    "headers = {\n",
    "    'api-key': config['OPENAI']['OPENAI_API_KEY'],\n",
    "    'Content-Type': 'application/json',\n",
    "    'Cache-Control': 'no-cache'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(engine, headers, prompt, **kwargs):\n",
    "\n",
    "    try:\n",
    "        return openai.Completion.create(\n",
    "            # Contact your team admin to get the name of your engine or model deployment.  \n",
    "            # This is the name that they used when they created the model deployment.\n",
    "            prompt=prompt,\n",
    "            engine=engine,\n",
    "            headers=headers,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    except openai.error.APIError as e:\n",
    "        # Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "\n",
    "    except openai.error.AuthenticationError as e:\n",
    "        # Handle Authentication error here, e.g. invalid API key\n",
    "        print(f\"OpenAI API returned an Authentication Error: {e}\")\n",
    "\n",
    "    except openai.error.APIConnectionError as e:\n",
    "        # Handle connection error here\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        # Handle connection error here\n",
    "        print(f\"Invalid Request Error: {e}\")\n",
    "\n",
    "    except openai.error.RateLimitError as e:\n",
    "        # Handle rate limit error\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "\n",
    "    except openai.error.ServiceUnavailableError as e:\n",
    "        # Handle Service Unavailable error\n",
    "        print(f\"Service Unavailable: {e}\")\n",
    "\n",
    "    except openai.error.Timeout as e:\n",
    "        # Handle request timeout\n",
    "        print(f\"Request timed out: {e}\")\n",
    "\n",
    "\n",
    "def get_embedding(text, engine, headers, **kwargs):\n",
    "\n",
    "    try:\n",
    "        response = openai.Embedding.create(\n",
    "            # Contact your team admin to get the name of your engine or model deployment.  \n",
    "            # This is the name that they used when they created the model deployment.\n",
    "            input=text,\n",
    "            engine=engine,\n",
    "            headers=headers,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "        embeddings = response['data'][0]['embedding']\n",
    "        return embeddings\n",
    "\n",
    "    except openai.error.APIError as e:\n",
    "        # Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "\n",
    "    except openai.error.AuthenticationError as e:\n",
    "        # Handle Authentication error here, e.g. invalid API key\n",
    "        print(f\"OpenAI API returned an Authentication Error: {e}\")\n",
    "\n",
    "    except openai.error.APIConnectionError as e:\n",
    "        # Handle connection error here\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        # Handle connection error here\n",
    "        print(f\"Invalid Request Error: {e}\")\n",
    "\n",
    "    except openai.error.RateLimitError as e:\n",
    "        # Handle rate limit error\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "\n",
    "    except openai.error.ServiceUnavailableError as e:\n",
    "        # Handle Service Unavailable error\n",
    "        print(f\"Service Unavailable: {e}\")\n",
    "\n",
    "    except openai.error.Timeout as e:\n",
    "        # Handle request timeout\n",
    "        print(f\"Request timed out: {e}\")\n",
    "\n",
    "\n",
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, engine, headers, max_response_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=engine,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        headers = headers\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "Você é um assistente que conhece tudo sobre podcasts. Você é capaz de responder perguntas sobre o podcast, sobre os episódios e sobre os convidados.\n",
      "\n",
      "[USER]\n",
      "A área de tecnologia da Petrobras, chamada de TIC está criando um programa de podcast através do qual pretende levar aos colaboradores da empresa temas sobre tecnologia tais como ChatGPT e IA generativa, por exemplo. Alguma sugestão de nome para esse podcast? Indique por favor uma lista de dez nomes bacanas para esse podcast.\n",
      "\n",
      "[ASSISTANT]\n",
      "1. \"TechPetro: Conexão e Inovação\"\n",
      "2. \"TIC Talk: Diálogos Tecnológicos da Petrobras\"\n",
      "3. \"PetroTech: A Nova Era Digital\"\n",
      "4. \"Onda Tecnológica Petrobras\"\n",
      "5. \"Petro IA: Transformando o Futuro\"\n",
      "6. \"PetroDigital: A Revolução TIC\"\n",
      "7. \"Conexão Petrobras: Tecnologia e Inovação\"\n",
      "8. \"TIC para Todos: A Tecnologia na Petrobras\"\n",
      "9. \"PetroChat: Conversas sobre IA e Tecnologia\"\n",
      "10. \"PetroInova: O Podcast de Tecnologia da Petrobras\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"Você é um assistente que conhece tudo sobre podcasts. Você é capaz de responder perguntas sobre o podcast, sobre os episódios e sobre os convidados.\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "\n",
    "user_message = \"A área de tecnologia da Petrobras, chamada de TIC está criando um programa de podcast através do qual pretende levar aos colaboradores da empresa temas sobre tecnologia tais como ChatGPT e IA generativa, por exemplo. Alguma sugestão de nome para esse podcast? Indique por favor uma lista de dez nomes bacanas para esse podcast.\"\n",
    "\n",
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "max_response_tokens = 500\n",
    "\n",
    "response = send_message(messages, engine=config['OPENAI']['CHATGPT_MODEL'], headers=headers, max_response_tokens=max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Embeddings API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embedding(text=\"Olá, mundo!\", engine=config['OPENAI']['EMBEDDINGS_MODEL'], headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Completion API (deprecated)\n",
    "\n",
    "A API de Completion foi descontinuada pela Open AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_completion(engine=config['OPENAI']['COMPLETIONS_MODEL'], headers=headers, prompt=\"Era uma vez, um menino chamado Romeu e uma menina chamada Julieta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uff-sentiment-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
